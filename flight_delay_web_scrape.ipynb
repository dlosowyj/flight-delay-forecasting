{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f6b4a0-7258-460a-92b9-41c0184ff1e3",
   "metadata": {},
   "source": [
    "# Flight Delay Web Scraping\n",
    "## Goal\n",
    "This notebook pulls data from the US government Bureau of Transportation Statistics (BTS) website https://www.transtats.bts.gov/ontime/departures.aspx to catalogue flight delays from the 33 busiest airports in the US. \n",
    "\n",
    "## Notes About the Data\n",
    "As a US agency, BTS (unsurprisingly, not the K-pop band) only catalogues delays at US airports for US-based airlines. This means that major international carriers like Lufthansa, KLM, Air Canada, etc are not included in this database. I have also made the decision to only pull data from the 33 busiest airports rather than all of the airports, largely due to time constraints. Even these 33 airports took several hours to run, nevermind the full list. (As a side note, I chose 33 airports because the 33rd busiest airport is PDX and I live in Portland.) I do not expect major impacts to my analysis as a result fo these caveats although it could be helpful to have flight delay data from all airports as delays in a flight leaving one airport could certainly correlate with delays in that same flight arriving and departing the next airport. \n",
    "\n",
    "## Brief Overview\n",
    "Here, web scraping is done in two main parts:\n",
    "1. The full list of airports and airlines is gathered from the dropdowns.\n",
    "2. We cycle through the busiest airports and check all airlines for each of those airports.\n",
    "\n",
    "## Detailed Overview\n",
    "The selenium package is the main mover and shaker in this notebook. I use it to visit the BTS website and examine the dropdowns for the airports and airlines to see what data is availabile. Note that the website shows every airline for every airport even if an airline does not service a particular airport. This only becomes clear when you pull the data and there is no flight delay information for said combination of airline and aiport.\n",
    "\n",
    "Once I identified the airports that had data, I consolidated the 33 busiest ones (per Wikipedia https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_the_United_States) into a list, created combinations of each of these with the available airlines, and then cycled through each of the combinations. For each combination, I selected the checkboxes to provide all the data from January 2021 through September 2025 and changed the dropdowns on the website to the correct airline and airport and requested data for delays. After waiting for the table to load, I download the csv and wait up to 300 seconds for the csv to be fully present on my local machine. This extended time is necessary due to internet slowdowns as well as the huge files for certain combinations (e.g. Delta at ATL is over 100 MB). I then save the delay information with the airline and airport names before moving on to the next combination.\n",
    "\n",
    "## Future Improvements\n",
    "This web scraping tool already handles most events like the file like not being fully downloaded and page loading delays, but more time could be put into resolving the full range of exceptions in a  more automated way. It would also be nice if there was a way to speed up the waiting time when it isn't necessary. For instance, a lot of time is spent waiting on combinations of airlines and airports that simply do not exist. Creating a list of all existing combinations of airlines and airports could save much of this waiting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddda4f4-464b-4b73-bed7-382c35e6d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Setup\n",
    "options = Options()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# Disable \"Save As\" dialog and set default download directory\n",
    "download_dir = 'C:/Users/dloso/Downloads'\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = 'https://www.transtats.bts.gov/ontime/departures.aspx' # Replace with the actual page URL\n",
    "driver.get(url)\n",
    "\n",
    "# Get list of all airports and airlines\n",
    "try:\n",
    "    dropdown_element = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.NAME, \"cboAirport\")))\n",
    "    select_airport = Select(dropdown_element)\n",
    "    dropdown_element2 = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.NAME, \"cboAirline\")))\n",
    "    select_airline = Select(dropdown_element2)\n",
    "    airport_options = [option.get_attribute('value') for option in select_airport.options]\n",
    "    airline_options = [option.get_attribute('value') for option in select_airline.options]\n",
    "except Exception as e:\n",
    "    print(f'An error has occurred when getting the airport/airline lists: {e}')\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9aaabd0-b524-4b80-ae9b-8daf2f031f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in while loop\n",
      "Airport: ATL\tAirline: TZ\n",
      "No data.\n",
      "Airport: ATL\tAirline: FL\n",
      "No data.\n",
      "Airport: ATL\tAirline: AS\n",
      "Waiting for download in: C:/Users/dloso/Downloads/Detailed_Statistics_Departures\n",
      "Download complete.\n",
      "File 'C:/Users/dloso/Downloads/Detailed_Statistics_Departures.csv' renamed to 'C:/Users/dloso/Downloads/test/ATL_AS_Delays.csv' successfully.\n",
      "Airport: ATL\tAirline: G4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     79\u001b[39m submit_button.click()\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# wait for the page to reload\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Check if there is data for this combination of airport and airline\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# data_present = driver.find_elements_by_xpath(\"//*[contains(text(), 'No data found for the above selection')]\")\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# if data_present:\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mNo data found for the above selection\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m driver.page_source:\n\u001b[32m     90\u001b[39m         \u001b[38;5;66;03m# click the button to download the csv\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tempfile\n",
    "import random\n",
    "\n",
    "# Pre-create combos with airlines so that you can easily pick up from where you left off\n",
    "busiest_airports = ['ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'JFK', 'CLT', 'LAS', 'MCO',\n",
    "                    'MIA', 'PHX', 'SEA', 'SFO', 'EWR', 'IAH', 'BOS', 'MSP', 'FLL',\n",
    "                    'LGA', 'DTW', 'PHL', 'SLC', 'BWI', 'IAD', 'SAN', 'DCA', 'TPA',\n",
    "                    'BNA', 'AUS', 'HNL', 'MDW', 'DAL', 'PDX']\n",
    "airport_airline_combos = list(itertools.product(busiest_airports, airline_options))\n",
    "num_combos = len(busiest_airports) * len(airline_options)\n",
    "\n",
    "# See if the program has crashed before and start from the crashed index. Otherwise start at 0\n",
    "PROGRESS_FILE = 'checkpoint.json'\n",
    "if os.path.exists(PROGRESS_FILE):\n",
    "    with open(PROGRESS_FILE, 'r') as f:\n",
    "        combo_index = json.load(f).get('combo_index', 0)\n",
    "else:\n",
    "    combo_index = 0\n",
    "\n",
    "while combo_index < num_combos:\n",
    "    # Setup\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"detach\", True)\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    # Disable \"Save As\" dialog and set default download directory\n",
    "    prefs = {\n",
    "        \"download.default_directory\": download_dir,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True\n",
    "    }\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    url = 'https://www.transtats.bts.gov/ontime/departures.aspx' # Replace with the actual page URL\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Select all statistics, days, months, and years 2021-2025\n",
    "        checkboxStats = driver.find_element(By.NAME, \"chkAllStatistics\")\n",
    "        driver.execute_script(\"arguments[0].click();\", checkboxStats)\n",
    "        checkboxMonths = driver.find_element(By.NAME, \"chkAllMonths\")\n",
    "        driver.execute_script(\"arguments[0].click();\", checkboxMonths)\n",
    "        chkAllDays = driver.find_element(By.NAME, \"chkAllDays\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chkAllDays)\n",
    "        chk2021 = driver.find_element(By.ID, \"chkYears_34\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chk2021)\n",
    "        chk2022 = driver.find_element(By.ID, \"chkYears_35\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chk2022)\n",
    "        chk2023 = driver.find_element(By.ID, \"chkYears_36\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chk2023)\n",
    "        chk2024 = driver.find_element(By.ID, \"chkYears_37\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chk2024)\n",
    "        chk2025 = driver.find_element(By.ID, \"chkYears_38\")\n",
    "        driver.execute_script(\"arguments[0].click();\", chk2025)\n",
    "\n",
    "        # for each airport\n",
    "        for i in range(combo_index, num_combos):\n",
    "            # select the current airport\n",
    "            cur_airport = airport_airline_combos[i][0]\n",
    "            cur_airline = airport_airline_combos[i][1]\n",
    "            dropdown_element = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.NAME, \"cboAirport\")))\n",
    "            select_airport = Select(dropdown_element)\n",
    "            select_airport.select_by_value(cur_airport)\n",
    "            dropdown_element2 = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.NAME, \"cboAirline\")))\n",
    "            select_airline = Select(dropdown_element2)\n",
    "            select_airline.select_by_value(cur_airline)\n",
    "\n",
    "            print(f\"Airport: {cur_airport}\\tAirline: {cur_airline}\")\n",
    "\n",
    "            # Click the button to generate the csv\n",
    "            submit_button = driver.find_element(By.NAME, \"btnSubmit\") # Replace with actual locator\n",
    "            submit_button.click()\n",
    "\n",
    "            # wait for the page to reload\n",
    "            time.sleep(random.uniform(3, 7))\n",
    "\n",
    "            try:\n",
    "                # Check if there is data for this combination of airport and airline\n",
    "                # data_present = driver.find_elements_by_xpath(\"//*[contains(text(), 'No data found for the above selection')]\")\n",
    "                \n",
    "                # if data_present:\n",
    "                if 'No data found for the above selection' not in driver.page_source:\n",
    "                    # click the button to download the csv\n",
    "                    download_button = driver.find_element(By.ID, \"DL_CSV\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", download_button)\n",
    "                \n",
    "                    # Wait for the download to complete\n",
    "                    current_file_name = \"C:/Users/dloso/Downloads/Detailed_Statistics_Departures.csv\"\n",
    "                    # new_file_name = 'C:/Users/dloso/Documents/Data Science/flight-delay-forecasting/data/delays/' \\\n",
    "                    #     + cur_airport + '_' + cur_airline + '_Delays.csv'\n",
    "                    new_file_name = 'C:/Users/dloso/Downloads/test/' \\\n",
    "                        + cur_airport + '_' + cur_airline + '_Delays.csv'\n",
    "                    \n",
    "                    download_path = 'C:/Users/dloso/Downloads/Detailed_Statistics_Departures'\n",
    "                    start_time = time.time()\n",
    "                    timeout = 300\n",
    "                    poll_interval = 2\n",
    "                    print(f\"Waiting for download in: {download_path}\")\n",
    "                    \n",
    "                    while time.time() - start_time < timeout:\n",
    "                        # Check for any temporary/partial file extensions\n",
    "                        # Common ones: .crdownload (Chrome), .part (Firefox/others), .tmp\n",
    "                        temp_files = glob.glob(download_path + '*.crdownload') + \\\n",
    "                                     glob.glob(download_path + '*.part') + \\\n",
    "                                     glob.glob(download_path + '*.tmp')\n",
    "                        \n",
    "                        # Check for the expected final file(s) using the pattern\n",
    "                        completed_files = glob.glob('C:/Users/dloso/Downloads/Detailed_Statistics_Departures.csv')\n",
    "                \n",
    "                        # If there are completed files and no temporary files, the download is likely done\n",
    "                        if completed_files and not temp_files:\n",
    "                            print('Download complete.')\n",
    "                            # Return the path(s) of the successfully downloaded file(s)\n",
    "                            break\n",
    "                        \n",
    "                        print(\".\", end=\"\", flush=True) # Print a dot to show activity\n",
    "                        time.sleep(poll_interval)\n",
    "                    \n",
    "                    try:\n",
    "                        # Rename the file\n",
    "                        os.rename(current_file_name, new_file_name)\n",
    "                        while Path(current_file_name).exists() and not Path(new_file_name).exists():\n",
    "                            time.sleep(1)\n",
    "                        \n",
    "                        print(f\"File '{current_file_name}' renamed to '{new_file_name}' successfully.\")\n",
    "\n",
    "                        # Update the json file with the next index using a temporary file to mitigate corruption in the event of a crash\n",
    "                        with tempfile.NamedTemporaryFile('w', delete=False) as tf:\n",
    "                            json.dump({'combo_index': i + 1}, tf)\n",
    "                            temp_name = tf.name\n",
    "                        os.replace(temp_name, PROGRESS_FILE)\n",
    "                        \n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Error: The file '{current_file_name}' was not found.\")\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Error: The destination file '{new_file_name}' already exists.\")\n",
    "                        if cur_airline == 'MQ':\n",
    "                            print(f'MQ airline--appending a 2 to the file.')\n",
    "                            # new_file_name = 'C:/Users/dloso/Documents/Data Science/flight-delay-forecasting/data/delays/' \\\n",
    "                                # + cur_airport + '_' + cur_airline + '_2_Delays.csv'\n",
    "                            new_file_name = 'C:/Users/dloso/Downloads/test/' \\\n",
    "                                + cur_airport + '_' + cur_airline + '_2_Delays.csv'\n",
    "                            os.rename(current_file_name, new_file_name)\n",
    "                    except Exception as e:\n",
    "                        print(f\"An unexpected error occurred during renaming: {e}\")\n",
    "\n",
    "                else:\n",
    "                    raise ValueError('')\n",
    "            except Exception as e:\n",
    "                print(f'No data.')\n",
    "\n",
    "            combo_index += 1\n",
    "    except Exception as e:\n",
    "        print(f'Program errored out--will restart at current airport-airline combo {combo_index}. {e}')\n",
    "        # Define the pattern for files to delete (e.g., all files ending with '.txt')\n",
    "        file_pattern = '*.crdownload' \n",
    "        # Define the directory path ('.' refers to the current directory)\n",
    "        directory_path = 'C:/Users/dloso/Downloads/' \n",
    "        \n",
    "        # Construct the full pattern to search for\n",
    "        search_pattern = os.path.join(directory_path, file_pattern)\n",
    "        files_to_remove = glob.glob(search_pattern)\n",
    "        \n",
    "        print(f\"Files found to remove: {files_to_remove}\")\n",
    "        \n",
    "        for file_path in files_to_remove:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed: {file_path}\")\n",
    "            except OSError as e:\n",
    "                # Handle potential errors like permission issues, or if it's a directory\n",
    "                print(f\"Error removing {file_path}: {e.strerror}\")\n",
    "                \n",
    "        # Define the pattern for files to delete (e.g., all files ending with '.txt')\n",
    "        file_pattern = 'Detailed_Statistics_Departures*' \n",
    "        # Define the directory path ('.' refers to the current directory)\n",
    "        directory_path = 'C:/Users/dloso/Downloads/' \n",
    "        \n",
    "        # Construct the full pattern to search for\n",
    "        search_pattern = os.path.join(directory_path, file_pattern)\n",
    "        files_to_remove = glob.glob(search_pattern)\n",
    "        \n",
    "        print(f\"Files found to remove: {files_to_remove}\")\n",
    "        \n",
    "        for file_path in files_to_remove:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed: {file_path}\")\n",
    "            except OSError as e:\n",
    "                # Handle potential errors like permission issues, or if it's a directory\n",
    "                print(f\"Error removing {file_path}: {e.strerror}\")\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0efaa4-3361-4356-b4f9-0838f66d3cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
